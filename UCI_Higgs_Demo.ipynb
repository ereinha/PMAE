{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ereinha/PMAE/blob/main/UCI_Higgs_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljNAg7kGW574"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone PMAE"
      ],
      "metadata": {
        "id": "3EXemE1_4YuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PMAE"
      ],
      "metadata": {
        "id": "sKykettazMKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "DRcXqGl2yelH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-nzdUw2W579"
      },
      "outputs": [],
      "source": [
        "import train\n",
        "import utils\n",
        "import test\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from models import classifier, pmae\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NICDsmf4W57-"
      },
      "outputs": [],
      "source": [
        "# Download the files from UCI ML repository\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\n",
        "!gzip -d HIGGS.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrAR832MW57-"
      },
      "outputs": [],
      "source": [
        "# Read in the csv\n",
        "data = pd.read_csv('./HIGGS.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4B-wGW7W57_"
      },
      "outputs": [],
      "source": [
        "# Split the data and labels\n",
        "X = data.iloc[:,1:]\n",
        "y = data.iloc[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waZwM1uwW57_"
      },
      "outputs": [],
      "source": [
        "# Get the inputs and outputs\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIOYJcNZW58A"
      },
      "outputs": [],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-9jTk0EW58A"
      },
      "outputs": [],
      "source": [
        "# Remove high level features and add 0 padding to line up related quantities\n",
        "X = np.delete(X, obj=np.s_[X.shape[1]-7:X.shape[1]], axis=-1)\n",
        "X = np.insert(X, obj=np.s_[3:4], values=0, axis=-1)\n",
        "X = np.insert(X, obj=np.s_[5:6], values=0, axis=-1)\n",
        "X = np.insert(X, obj=np.s_[7:8], values=0, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPS1zvW3W58B"
      },
      "outputs": [],
      "source": [
        "# Visualizing the data\n",
        "names = [\"lepton pT\", \"lepton eta\", \"lepton phi\", \"Zero Padding\",\n",
        "         \"missing energy magnitude\", \"Zero Padding\", \"missing energy phi\", \"Zero Padding\",\n",
        "         \"jet 1 pt\", \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\",\n",
        "         \"jet 2 pt\", \"jet 2 eta\", \"jet 2 phi\", \"jet 2 b-tag\",\n",
        "         \"jet 3 pt\", \"jet 3 eta\", \"jet 3 phi\", \"jet 3 b-tag\",\n",
        "         \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\"]\n",
        "\n",
        "fig, axes = plt.subplots(6,4, figsize=(15,20))\n",
        "fig.tight_layout(pad=4)\n",
        "\n",
        "X_higgs = X[y==1]\n",
        "X_nohiggs = X[y==0]\n",
        "y_higgs = y[y==1]\n",
        "y_nohiggs = y[y==0]\n",
        "\n",
        "for i in range(len(axes)):\n",
        "    for j in range(len(axes[0])):\n",
        "        axes[i,j].hist(X_higgs[:,i*4+j], histtype='step', stacked=False, density=1, bins=30, label='Higgs')\n",
        "        axes[i,j].hist(X_nohiggs[:,i*4+j], histtype='step', stacked=False, density=1, bins=30, label='Background')\n",
        "        axes[i,j].set_title(names[i*4+j])\n",
        "        axes[i,j].set_xlabel(names[i*4+j] + ' scaled')\n",
        "        axes[i,j].legend()\n",
        "        axes[i,j].set_ylabel(\"Proportion of data (density=1)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ihXcL6FW58C"
      },
      "outputs": [],
      "source": [
        "print(len(X_higgs))\n",
        "print(len(X_nohiggs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxvhcqKWW58C"
      },
      "outputs": [],
      "source": [
        "# Create data labels for Higgs and Non-Higgs (ttbar) data (for the UCI set we can also use the y values)\n",
        "labels_hh = np.ones(len(X_higgs))\n",
        "labels_tt = np.zeros(len(X_nohiggs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNFIeE1FW58C"
      },
      "outputs": [],
      "source": [
        "# Split the Higgs data into train and test sets .8, .1, .1\n",
        "X_hh_train, X_val1, labels_hh_train, labels_val1 = train_test_split(X_higgs, labels_hh, test_size=0.2, random_state=42)\n",
        "X_hh_val, X_hh_test, labels_hh_val, labels_hh_test = train_test_split(X_val1, labels_val1, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_adEoGKW58C"
      },
      "outputs": [],
      "source": [
        "# Normalize data relative to the Higgs train data\n",
        "x_scaler = StandardScaler()\n",
        "X_hh_train = x_scaler.fit_transform(X_hh_train)\n",
        "X_hh_val = x_scaler.transform(X_hh_val)\n",
        "X_hh_test = x_scaler.transform(X_hh_test)\n",
        "X_nohiggs = x_scaler.transform(X_nohiggs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oRjqh1QW58C"
      },
      "outputs": [],
      "source": [
        "# Split the ttbar data into train and test sets .8, .1, .1\n",
        "X_tt_train, X_val1, labels_tt_train, labels_val1 = train_test_split(X_nohiggs, labels_tt, test_size=0.2, random_state=42)\n",
        "X_tt_val, X_tt_test, labels_tt_val, labels_tt_test = train_test_split(X_val1, labels_val1, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn0Ri16gW58D"
      },
      "outputs": [],
      "source": [
        "print(np.shape(X_hh_train), np.shape(X_tt_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAwCuYvSW58D"
      },
      "outputs": [],
      "source": [
        "# Reshape the data to have shape [batch_size,particles,features]\n",
        "X_hh_train = X_hh_train.reshape(X_hh_train.shape[0],6,4)\n",
        "X_hh_val = X_hh_val.reshape(X_hh_val.shape[0],6,4)\n",
        "X_hh_test = X_hh_test.reshape(X_hh_test.shape[0],6,4)\n",
        "X_tt_train = X_tt_train.reshape(X_tt_train.shape[0],6,4)\n",
        "X_tt_val = X_tt_val.reshape(X_tt_val.shape[0],6,4)\n",
        "X_tt_test = X_tt_test.reshape(X_tt_test.shape[0],6,4)\n",
        "\n",
        "# Compute some quantities to be used for calculation\n",
        "phi_limit = np.max((abs(np.max(X_hh_train[:,0,2])), abs(np.min(X_hh_train[:,0,2])))) # Only need one value assuming phi distrubtions are all uniform\n",
        "lower_pt_limit = [np.min(X_hh_train[:,0,0]), np.min(X_hh_train[:,1,0]), np.min(X_hh_train[:,2,0]), np.min(X_hh_train[:,3,0]), np.min(X_hh_train[:,4,0]), np.min(X_hh_train[:,5,0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVeGYuU1W58D"
      },
      "outputs": [],
      "source": [
        "# Create a mixed sample of Higgs and ttbar data\n",
        "X_train = np.append(X_hh_train, X_tt_train, axis=0)\n",
        "X_val = np.append(X_hh_val, X_tt_val, axis=0)\n",
        "X_test = np.append(X_hh_test, X_tt_test, axis=0)\n",
        "labels_train = np.append(labels_hh_train, labels_tt_train, axis=0)\n",
        "labels_val = np.append(labels_hh_val, labels_tt_val, axis=0)\n",
        "labels_test = np.append(labels_hh_test, labels_tt_test, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeUqquShW58D"
      },
      "outputs": [],
      "source": [
        "# Load a config file from a json\n",
        "with open('./configs/uci_higgs_config_demo.json', 'r') as f:\n",
        "    config = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMmm-ifuW58D"
      },
      "outputs": [],
      "source": [
        "model_name = model_name = f'Model_D{config[\"d_model\"]}_H{config[\"num_heads\"]}_L{config[\"num_layers\"]}_F{config[\"d_ff\"]}_Dr{config[\"dropout\"]}_B{config[\"batch_size\"]}_T{config[\"test_batch_size\"]}_RE{config[\"resume_epoch\"]}_NE{config[\"num_epochs\"]}_ES{config[\"epochs_to_saturate\"]}_IM{config[\"init_momentum\"]}_MM{config[\"max_momentum\"]}_ILR{config[\"init_lr\"]}_MSL{config[\"max_seq_len\"]}_Mk{config[\"mask\"]}_A{config[\"alpha\"]}_B{config[\"beta\"]}_G{config[\"gamma\"]}_WD{config[\"weight_decay\"]}_MLR{config[\"min_lr\"]}_LD{config[\"lr_decay\"]}_CIF{config[\"class_input_features\"]}_CFD{config[\"class_ff_dim\"]}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIQwdO4IW58D"
      },
      "outputs": [],
      "source": [
        "# Set device to use gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1IqOjV1W58E"
      },
      "outputs": [],
      "source": [
        "# Build the autoencoder model\n",
        "tae = pmae.TransformerAutoencoder(config['d_model'], config['num_heads'], config['num_layers'], config['d_ff'], config['max_seq_len'], config['output_vars'], config['dropout'], device)\n",
        "# Build classifier\n",
        "classifier = classifier.BinaryClassifier(config['class_input_features'], config['class_ff_dim'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35Y1m572W58E"
      },
      "outputs": [],
      "source": [
        "# Send the models to gpu if possible\n",
        "tae.to(device)\n",
        "classifier.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04PHqNBpW58E"
      },
      "outputs": [],
      "source": [
        "# Assign the criterion\n",
        "criterion = utils.custom_loss(phi_limit, config['alpha'], config['beta'], config['gamma'], config['delta'], config['output_vars'])\n",
        "criterion_2 = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49JQ1qLqW58E"
      },
      "outputs": [],
      "source": [
        "# Instantiate the dataset and DataLoader\n",
        "train_data = utils.DataLabelDataset(X_train, labels_train)\n",
        "train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
        "val_data = utils.DataLabelDataset(X_val, labels_val)\n",
        "val_loader = DataLoader(val_data, batch_size=config['test_batch_size'], shuffle=True)\n",
        "test_data = utils.DataLabelDataset(X_test, labels_test)\n",
        "test_loader = DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKHftMngW58E"
      },
      "outputs": [],
      "source": [
        "# Build the optimizers\n",
        "optimizer = utils.SGDWithSaturatingMomentumAndDecay(tae.parameters(), lr=init_lr, momentum=config['min_momentum'], max_momentum=config['max_momentum'],\n",
        "                                                    epochs_to_saturate=config['epochs_to_saturate'], batches_per_epoch=len(train_loader), weight_decay=0,\n",
        "                                                    lr_decay=lr_decay, min_lr=min_lr, resume_epoch=resume_epoch)\n",
        "optimizer_2 = utils.SGDWithSaturatingMomentumAndDecay(list(tae.parameters())+list(classifier.parameters()), lr=init_lr, momentum=config['min_momentum'],\n",
        "                                                      max_momentum=config['max_momentum'],  epochs_to_saturate=config['epochs_to_saturate'],\n",
        "                                                      batches_per_epoch=len(train_loader), weight_decay=config['weight_decay'], lr_decay=config['lr_decay'],\n",
        "                                                      min_lr=config['min_lr'], resume_epoch=config['resume_epoch'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp5Bp1YYW58E"
      },
      "outputs": [],
      "source": [
        "train_loader, val_loader, models, device, optimizer, criterion, model_type, output_vars,\n",
        "\n",
        "# Train the model\n",
        "val_loss_min = train.train(train_loader, val_loader, [tae], device, optimizer, criterion, 'autoencoder', config['output_vars'], mask=config['mask'],\n",
        "                           num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs', model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvfd6X_3W58F"
      },
      "outputs": [],
      "source": [
        "val_loss_min = train.train(train_loader, val_loader, [tae], device, optimizer_2, criterion_2, 'classifier_partial', config['output_vars'], mask=config['mask'],\n",
        "                           num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs', model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNIcVMUYW58F"
      },
      "outputs": [],
      "source": [
        "val_loss_min = train.train(train_loader, val_loader, [tae], device, optimizer_2, criterion_2, 'classifier_full', config['output_vars'], mask=config['mask'],\n",
        "                           num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs', model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMJZvTIKW58F"
      },
      "outputs": [],
      "source": [
        "# Parse a json config interpretation from a model name string\n",
        "config = parse_model_name(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7gsiUZ-W58F"
      },
      "outputs": [],
      "source": [
        "# Build the autoencoder model\n",
        "tae = pmae.TransformerAutoencoder(config['d_model'], config['num_heads'], config['num_layers'], config['d_ff'], config['max_seq_len'], config['output_vars'], config['dropout'], device)\n",
        "# Build classifier\n",
        "classifier = classifier.BinaryClassifier(config['class_input_features'], config['class_ff_dim'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwycBjaZW58F"
      },
      "outputs": [],
      "source": [
        "tae.load_state_dict(torch.load('./saved_models/uci_higgs/TAE_best_' + model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7xllnhUW58F"
      },
      "outputs": [],
      "source": [
        "# Test the model and generate some plots\n",
        "classifier.load_state_dict(torch.load('./saved_models/uci_higgs/Classifier_full_best_' + model_name))\n",
        "test.test(test_loader, test_batch_size, X_test, labels_test, names, [tae, classifier], mask, device, x_scaler, config['output_vars'], 'full', model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iECzjpf3W58F"
      },
      "outputs": [],
      "source": [
        "classifier.load_state_dict(torch.load('./saved_models/uci_higgs/Classifier_partial_best_' + model_name))\n",
        "test.test(test_loader, test_batch_size, X_test, labels_test, names, [tae, classifier], mask, device, x_scaler, config['output_vars'], 'partial', model_name)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}