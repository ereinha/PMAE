{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import utils\n",
    "import test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import train_test_split\n",
    "from matplotlib.pyplot import plt\n",
    "import json\n",
    "from models import classifier, vmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\n",
    "!gzip -d HIGGS.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./HIGGS.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, obj=np.s_[X.shape[1]-7:X.shape[1]], axis=-1)\n",
    "X = np.insert(X, obj=np.s_[3:4], values=0, axis=-1)\n",
    "X = np.insert(X, obj=np.s_[5:6], values=0, axis=-1)\n",
    "X = np.insert(X, obj=np.s_[7:8], values=0, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"lepton pT\", \"lepton eta\", \"lepton phi\", \"Zero Padding\",\n",
    "         \"missing energy magnitude\", \"Zero Padding\", \"missing energy phi\", \"Zero Padding\",\n",
    "         \"jet 1 pt\", \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\",\n",
    "         \"jet 2 pt\", \"jet 2 eta\", \"jet 2 phi\", \"jet 2 b-tag\",\n",
    "         \"jet 3 pt\", \"jet 3 eta\", \"jet 3 phi\", \"jet 3 b-tag\",\n",
    "         \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\"]\n",
    "\n",
    "fig, axes = plt.subplots(6,4, figsize=(15,20))\n",
    "fig.tight_layout(pad=4)\n",
    "\n",
    "X_higgs = X[y==1]\n",
    "X_nohiggs = X[y==0]\n",
    "y_higgs = y[y==1]\n",
    "y_nohiggs = y[y==0]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    for j in range(len(axes[0])):\n",
    "        axes[i,j].hist(X_higgs[:,i*4+j], histtype='step', stacked=False, density=1, bins=30, label='Higgs')\n",
    "        axes[i,j].hist(X_nohiggs[:,i*4+j], histtype='step', stacked=False, density=1, bins=30, label='Background')\n",
    "        axes[i,j].set_title(names[i*4+j])\n",
    "        axes[i,j].set_xlabel(names[i*4+j] + ' scaled')\n",
    "        axes[i,j].legend()\n",
    "        axes[i,j].set_ylabel(\"Proportion of data (density=1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_higgs))\n",
    "print(len(X_nohiggs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hh = np.ones(len(X_higgs))\n",
    "labels_tt = np.zeros(len(X_nohiggs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hh_train, X_val1, labels_hh_train, labels_val1 = train_test_split(X_higgs, labels_hh, test_size=0.2, random_state=42)\n",
    "X_hh_val, X_hh_test, labels_hh_val, labels_hh_test = train_test_split(X_val1, labels_val1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "x_scaler = StandardScaler()\n",
    "X_hh_train = x_scaler.fit_transform(X_hh_train)\n",
    "X_hh_val = x_scaler.transform(X_hh_val)\n",
    "X_hh_test = x_scaler.transform(X_hh_test)\n",
    "X_nohiggs = x_scaler.transform(X_nohiggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tt_train, X_val1, labels_tt_train, labels_val1 = train_test_split(X_nohiggs, labels_tt, test_size=0.2, random_state=42)\n",
    "X_tt_val, X_tt_test, labels_tt_val, labels_tt_test = train_test_split(X_val1, labels_val1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_hh_train), np.shape(X_tt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hh_train = X_hh_train.reshape(X_hh_train.shape[0],6,4)\n",
    "X_hh_val = X_hh_val.reshape(X_hh_val.shape[0],6,4)\n",
    "X_hh_test = X_hh_test.reshape(X_hh_test.shape[0],6,4)\n",
    "X_tt_train = X_tt_train.reshape(X_tt_train.shape[0],6,4)\n",
    "X_tt_val = X_tt_val.reshape(X_tt_val.shape[0],6,4)\n",
    "X_tt_test = X_tt_test.reshape(X_tt_test.shape[0],6,4)\n",
    "\n",
    "phi_limit = np.max((abs(np.max(X_hh_train[:,0,2])), abs(np.min(X_hh_train[:,0,2])))) # Only need one value assuming phi distrubtions are all uniform\n",
    "lower_pt_limit = [np.min(X_hh_train[:,0,0]), np.min(X_hh_train[:,1,0]), np.min(X_hh_train[:,2,0]), np.min(X_hh_train[:,3,0]), np.min(X_hh_train[:,4,0]), np.min(X_hh_train[:,5,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.append(X_hh_train, X_tt_train, axis=0)\n",
    "X_val = np.append(X_hh_val, X_tt_val, axis=0)\n",
    "X_test = np.append(X_hh_test, X_tt_test, axis=0)\n",
    "labels_train = np.append(labels_hh_train, labels_tt_train, axis=0)\n",
    "labels_val = np.append(labels_hh_val, labels_tt_val, axis=0)\n",
    "labels_test = np.append(labels_hh_test, labels_tt_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/uci_higgs.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the autoencoder model\n",
    "tae = vmae.TransformerAutoencoder(config['d_model'], config['num_heads'], config['num_layers'], config['d_ff'], config['max_seq_len'], config['dropout'], config['device'])\n",
    "# Build classifier\n",
    "classifier = classifier.BinaryClassifier(config['class_input_features'], config['class_ff_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae.to(device)\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the criterion\n",
    "criterion = utils.custom_loss(phi_limit, config['alpha'], config['beta'], config['gamma'])\n",
    "criterion_2 = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset and DataLoader\n",
    "train_data = utils.DataLabelDataset(X_train, labels_train)\n",
    "train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
    "val_data = utils.DataLabelDataset(X_val, labels_val)\n",
    "val_loader = DataLoader(val_data, batch_size=config['test_batch_size'], shuffle=True)\n",
    "test_data = utils.DataLabelDataset(X_test, labels_test)\n",
    "test_loader = DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = utils.SGDWithSaturatingMomentumAndDecay(tae.parameters(), lr=init_lr, momentum=config['min_momentum'], max_momentum=config['max_momentum'], epochs_to_saturate=config['epochs_to_saturate'], batches_per_epoch=len(train_loader), weight_decay=0, lr_decay=lr_decay, min_lr=min_lr, resume_epoch=resume_epoch)\n",
    "optimizer_2 = utils.SGDWithSaturatingMomentumAndDecay(list(tae.parameters())+list(classifier.parameters()), lr=init_lr, momentum=config['min_momentum'], max_momentum=config['max_momentum'],  epochs_to_saturate=config['epochs_to_saturate'], batches_per_epoch=len(train_loader), weight_decay=config['weight_decay'], lr_decay=config['lr_decay'], min_lr=config['min_lr'], resume_epoch=config['resume_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_min, val_loss_min_2 = train.train(train_loader, val_loader, tae, classifier, optimizer, optimizer_2, criterion, criterion_2, mask=config['mask'], num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.test(test_loader, test_batch_size, X_test, labels_test, tae, classifier, criterion, mask, x_scaler)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
