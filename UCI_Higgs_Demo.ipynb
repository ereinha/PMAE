{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import utils\n",
    "import test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import train_test_split\n",
    "from matplotlib.pyplot import plt\n",
    "import json\n",
    "from models import classifier, pmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the files from UCI ML repository\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\n",
    "!gzip -d HIGGS.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv\n",
    "data = pd.read_csv('./HIGGS.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data and labels\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs and outputs\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high level features and add 0 padding to line up related quantities\n",
    "X = np.delete(X, obj=np.s_[X.shape[1]-7:X.shape[1]], axis=-1)\n",
    "X = np.insert(X, obj=np.s_[3:4], values=0, axis=-1)\n",
    "X = np.insert(X, obj=np.s_[5:6], values=0, axis=-1)\n",
    "X = np.insert(X, obj=np.s_[7:8], values=0, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data\n",
    "names = [\"lepton pT\", \"lepton eta\", \"lepton phi\", \"Zero Padding\",\n",
    "         \"missing energy magnitude\", \"Zero Padding\", \"missing energy phi\", \"Zero Padding\",\n",
    "         \"jet 1 pt\", \"jet 1 eta\", \"jet 1 phi\", \"jet 1 b-tag\",\n",
    "         \"jet 2 pt\", \"jet 2 eta\", \"jet 2 phi\", \"jet 2 b-tag\",\n",
    "         \"jet 3 pt\", \"jet 3 eta\", \"jet 3 phi\", \"jet 3 b-tag\",\n",
    "         \"jet 4 pt\", \"jet 4 eta\", \"jet 4 phi\", \"jet 4 b-tag\"]\n",
    "\n",
    "fig, axes = plt.subplots(6,4, figsize=(15,20))\n",
    "fig.tight_layout(pad=4)\n",
    "\n",
    "X_higgs = X[y==1]\n",
    "X_nohiggs = X[y==0]\n",
    "y_higgs = y[y==1]\n",
    "y_nohiggs = y[y==0]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    for j in range(len(axes[0])):\n",
    "        axes[i,j].hist(X_higgs[:,i*4+j], histtype='step', stacked=False, density=1, bins=30, label='Higgs')\n",
    "        axes[i,j].hist(X_nohiggs[:,i*4+j], histtype='step', stacked=False, density=1, bins=30, label='Background')\n",
    "        axes[i,j].set_title(names[i*4+j])\n",
    "        axes[i,j].set_xlabel(names[i*4+j] + ' scaled')\n",
    "        axes[i,j].legend()\n",
    "        axes[i,j].set_ylabel(\"Proportion of data (density=1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_higgs))\n",
    "print(len(X_nohiggs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data labels for Higgs and Non-Higgs (ttbar) data (for the UCI set we can also use the y values)\n",
    "labels_hh = np.ones(len(X_higgs))\n",
    "labels_tt = np.zeros(len(X_nohiggs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Higgs data into train and test sets .8, .1, .1\n",
    "X_hh_train, X_val1, labels_hh_train, labels_val1 = train_test_split(X_higgs, labels_hh, test_size=0.2, random_state=42)\n",
    "X_hh_val, X_hh_test, labels_hh_val, labels_hh_test = train_test_split(X_val1, labels_val1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data relative to the Higgs train data\n",
    "x_scaler = StandardScaler()\n",
    "X_hh_train = x_scaler.fit_transform(X_hh_train)\n",
    "X_hh_val = x_scaler.transform(X_hh_val)\n",
    "X_hh_test = x_scaler.transform(X_hh_test)\n",
    "X_nohiggs = x_scaler.transform(X_nohiggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the ttbar data into train and test sets .8, .1, .1\n",
    "X_tt_train, X_val1, labels_tt_train, labels_val1 = train_test_split(X_nohiggs, labels_tt, test_size=0.2, random_state=42)\n",
    "X_tt_val, X_tt_test, labels_tt_val, labels_tt_test = train_test_split(X_val1, labels_val1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_hh_train), np.shape(X_tt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to have shape [batch_size,particles,features]\n",
    "X_hh_train = X_hh_train.reshape(X_hh_train.shape[0],6,4)\n",
    "X_hh_val = X_hh_val.reshape(X_hh_val.shape[0],6,4)\n",
    "X_hh_test = X_hh_test.reshape(X_hh_test.shape[0],6,4)\n",
    "X_tt_train = X_tt_train.reshape(X_tt_train.shape[0],6,4)\n",
    "X_tt_val = X_tt_val.reshape(X_tt_val.shape[0],6,4)\n",
    "X_tt_test = X_tt_test.reshape(X_tt_test.shape[0],6,4)\n",
    "\n",
    "# Compute some quantities to be used for calculation\n",
    "phi_limit = np.max((abs(np.max(X_hh_train[:,0,2])), abs(np.min(X_hh_train[:,0,2])))) # Only need one value assuming phi distrubtions are all uniform\n",
    "lower_pt_limit = [np.min(X_hh_train[:,0,0]), np.min(X_hh_train[:,1,0]), np.min(X_hh_train[:,2,0]), np.min(X_hh_train[:,3,0]), np.min(X_hh_train[:,4,0]), np.min(X_hh_train[:,5,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mixed sample of Higgs and ttbar data\n",
    "X_train = np.append(X_hh_train, X_tt_train, axis=0)\n",
    "X_val = np.append(X_hh_val, X_tt_val, axis=0)\n",
    "X_test = np.append(X_hh_test, X_tt_test, axis=0)\n",
    "labels_train = np.append(labels_hh_train, labels_tt_train, axis=0)\n",
    "labels_val = np.append(labels_hh_val, labels_tt_val, axis=0)\n",
    "labels_test = np.append(labels_hh_test, labels_tt_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a config file from a json\n",
    "with open('./configs/uci_higgs.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name = f'Model_D{config[\"d_model\"]}_H{config[\"num_heads\"]}_L{config[\"num_layers\"]}_F{config[\"d_ff\"]}_Dr{config[\"dropout\"]}_B{config[\"batch_size\"]}_T{config[\"test_batch_size\"]}_RE{config[\"resume_epoch\"]}_NE{config[\"num_epochs\"]}_ES{config[\"epochs_to_saturate\"]}_IM{config[\"init_momentum\"]}_MM{config[\"max_momentum\"]}_ILR{config[\"init_lr\"]}_MSL{config[\"max_seq_len\"]}_Mk{config[\"mask\"]}_A{config[\"alpha\"]}_B{config[\"beta\"]}_G{config[\"gamma\"]}_WD{config[\"weight_decay\"]}_MLR{config[\"min_lr\"]}_LD{config[\"lr_decay\"]}_CIF{config[\"class_input_features\"]}_CFD{config[\"class_ff_dim\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the autoencoder model\n",
    "tae = pmae.TransformerAutoencoder(config['d_model'], config['num_heads'], config['num_layers'], config['d_ff'], config['max_seq_len'], config['output_vars'], config['dropout'], device)\n",
    "# Build classifier\n",
    "classifier = classifier.BinaryClassifier(config['class_input_features'], config['class_ff_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the models to gpu if possible\n",
    "tae.to(device)\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the criterion\n",
    "criterion = utils.custom_loss(phi_limit, config['alpha'], config['beta'], config['gamma'], config['delta'], config['output_vars'])\n",
    "criterion_2 = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset and DataLoader\n",
    "train_data = utils.DataLabelDataset(X_train, labels_train)\n",
    "train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
    "val_data = utils.DataLabelDataset(X_val, labels_val)\n",
    "val_loader = DataLoader(val_data, batch_size=config['test_batch_size'], shuffle=True)\n",
    "test_data = utils.DataLabelDataset(X_test, labels_test)\n",
    "test_loader = DataLoader(test_data, batch_size=config['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the optimizers\n",
    "optimizer = utils.SGDWithSaturatingMomentumAndDecay(tae.parameters(), lr=init_lr, momentum=config['min_momentum'], max_momentum=config['max_momentum'], \n",
    "                                                    epochs_to_saturate=config['epochs_to_saturate'], batches_per_epoch=len(train_loader), weight_decay=0, \n",
    "                                                    lr_decay=lr_decay, min_lr=min_lr, resume_epoch=resume_epoch)\n",
    "optimizer_2 = utils.SGDWithSaturatingMomentumAndDecay(list(tae.parameters())+list(classifier.parameters()), lr=init_lr, momentum=config['min_momentum'], \n",
    "                                                      max_momentum=config['max_momentum'],  epochs_to_saturate=config['epochs_to_saturate'], \n",
    "                                                      batches_per_epoch=len(train_loader), weight_decay=config['weight_decay'], lr_decay=config['lr_decay'], \n",
    "                                                      min_lr=config['min_lr'], resume_epoch=config['resume_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, models, device, optimizer, criterion, model_type, output_vars,\n",
    "\n",
    "# Train the model\n",
    "val_loss_min = train.train(train_loader, val_loader, [tae], device, optimizer, criterion, 'autoencoder', config['output_vars'], mask=config['mask'],\n",
    "                           num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs', model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_min = train.train(train_loader, val_loader, [tae], device, optimizer_2, criterion_2, 'classifier_partial', config['output_vars'], mask=config['mask'],\n",
    "                           num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs', model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_min = train.train(train_loader, val_loader, [tae], device, optimizer_2, criterion_2, 'classifier_full', config['output_vars'], mask=config['mask'],\n",
    "                           num_epochs=config['num_epochs']-config['resume_epoch'], save_path='./saved_models/uci_higgs', model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a json config interpretation from a model name string\n",
    "config = parse_model_name(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the autoencoder model\n",
    "tae = pmae.TransformerAutoencoder(config['d_model'], config['num_heads'], config['num_layers'], config['d_ff'], config['max_seq_len'], config['output_vars'], config['dropout'], device)\n",
    "# Build classifier\n",
    "classifier = classifier.BinaryClassifier(config['class_input_features'], config['class_ff_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae.load_state_dict(torch.load('./saved_models/uci_higgs/TAE_best_' + model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model and generate some plots\n",
    "classifier.load_state_dict(torch.load('./saved_models/uci_higgs/Classifier_full_best_' + model_name))\n",
    "test.test(test_loader, test_batch_size, X_test, labels_test, names, [tae, classifier], mask, device, x_scaler, config['output_vars'], 'full', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_state_dict(torch.load('./saved_models/uci_higgs/Classifier_partial_best_' + model_name))\n",
    "test.test(test_loader, test_batch_size, X_test, labels_test, names, [tae, classifier], mask, device, x_scaler, config['output_vars'], 'partial', model_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
